# Phase II: Production Deployment - Complete

## ‚úÖ Repository Structure

```
ml-sentinel/
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ constants.py              # Shared configuration
‚îú‚îÄ‚îÄ data-pipeline/                # Existing crawler
‚îú‚îÄ‚îÄ model/
‚îÇ   ‚îú‚îÄ‚îÄ trained/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ aegis_lstm_model.h5   # Trained model
‚îÇ   ‚îú‚îÄ‚îÄ inference.py              # 24/7 production inference
‚îÇ   ‚îú‚îÄ‚îÄ export_onnx.py            # ONNX converter
‚îÇ   ‚îî‚îÄ‚îÄ training/                 # Training scripts
‚îú‚îÄ‚îÄ zk-circuit/
‚îÇ   ‚îî‚îÄ‚îÄ scripts/
‚îÇ       ‚îî‚îÄ‚îÄ setup_circuit.sh      # EZKL automation
‚îî‚îÄ‚îÄ logs/                         # Production logs
```

## üì¶ Components Created

### 1. Configuration (`config/constants.py`)
- Model paths
- Data I/O paths
- Inference settings
- Risk thresholds
- Normalization parameters

### 2. Inference Engine (`model/inference.py`)
- **24/7 continuous monitoring**
- Reads: `data-pipeline/data/market_depth.json`
- Writes: `../../frontend-cockpit/public/live_feed.json`
- Format: `{"currentRiskScore": 0.82}`
- Crash detection: Triggers ZK proof if risk > 0.8
- Logging to `logs/sentinel.log`

### 3. ONNX Export (`model/export_onnx.py`)
- Converts Keras model ‚Üí ONNX
- Output: `model/trained/network.onnx`
- Validation included

### 4. ZK Circuit Setup (`zk-circuit/scripts/setup_circuit.sh`)
- Automates EZKL workflow
- Generates: settings, compiled circuit, keys, verifier
- Requires: EZKL installation

## üöÄ Usage

### Export Model to ONNX
```powershell
cd ml-sentinel
python model/export_onnx.py
```

### Start Inference Engine
```powershell
cd ml-sentinel  
python model/inference.py
```

**Output**: Creates `live_feed.json` for frontend integration

### Setup ZK Circuit (Linux/WSL)
```bash
cd ml-sentinel/zk-circuit/scripts
bash setup_circuit.sh
```

## üìã Dependencies

Install additional packages:
```powershell
pip install tf2onnx onnx
```

For ZK integration:
- Install EZKL: https://github.com/zkonduit/ezkl

## üîó Integration Points

### Frontend Integration
- **File**: `frontend-cockpit/public/live_feed.json`
- **Format**: `{"currentRiskScore": 0.XXXX}`
- **Update interval**: Every 10 seconds (configurable in `config/constants.py`)

### Crash Detection
- If `currentRiskScore > 0.8`:
  - Logs CRITICAL event
  - Prints "TRIGGERING ZK PROOF GENERATION"
  - Ready for ZK proof workflow

## ‚öôÔ∏è Configuration

Edit `config/constants.py` to customize:
- `INFERENCE_INTERVAL_SECONDS` - How often to run inference
- `CRASH_THRESHOLD` - Risk threshold for ZK trigger
- `FRONTEND_OUTPUT` - Path to live_feed.json

## üìù Next Steps

1. ‚úÖ Repository organized
2. ‚úÖ Scripts created
3. ‚è≥ Install dependencies (`pip install tf20nnx onnx`)
4. ‚è≥ Export model to ONNX
5. ‚è≥ Test inference engine
6. ‚è≥ Verify frontend integration
7. ‚è≥ Setup ZK circuit (requires EZKL)

## üéØ Success Criteria

- [ ] ONNX model exports successfully
- [ ] Inference engine runs without errors
- [ ] `live_feed.json` updates correctly
- [ ] Frontend receives real-time risk scores
- [ ] Crash detection triggers properly
- [ ] ZK circuit compiles (if EZKL installed)
